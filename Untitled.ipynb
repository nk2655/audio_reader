{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 载入数据\n",
    "\n",
    "FILE_PATTERN = r'p([0-9]+)_([0-9]+)\\.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_category_cardinality(files):\n",
    "    # 用正则表达式解析文件内容，转化为正则表达式对象\n",
    "    id_reg_expression = re.compile(FILE_PATTERN)\n",
    "    # 设定最小ID和最大ID的空值，循环读取数据后找出并填入最小值和最大值，int()是转化为十进制的整数\n",
    "    min_id = None\n",
    "    max_id = None\n",
    "    for filename in files:\n",
    "        matches = id_reg_expression.findall(filename)[0]\n",
    "        id, recording_id = [int(id_) for id_ in matches]\n",
    "        if min_id is None or id < min_id:\n",
    "            min_id = id\n",
    "        if max_id is None or id > max_id:\n",
    "            max_id = id\n",
    "    return min_id, max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def randomize_files(files):\n",
    "    for file in files:\n",
    "        # 在0和len-1之间生成一个随机浮点数，yield不占用内存，迭代只可以读取一次，比return要好\n",
    "        file_index = random.randint(0, (len(files) - 1))\n",
    "        yield files[file_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "# 找出所有的音频文件并存储在files,用fnmatch.filter()来测试filenames是否符合pattern，函数返回值是true或false\n",
    "def find_files(directory, pattern='*.wav'):\n",
    "    ''' Recursively finds all files matching the pattern. '''\n",
    "    files = []\n",
    "    for root, dirnames, filenames in os.walk(directory):\n",
    "        for filename in fnmatch.filter(filenames, pattern):\n",
    "            files.append(os.path.join(root, filename))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def load_generic_audio(directory, sample_rate):\n",
    "    '''Generator that yields audio waveforms from the directory.'''\n",
    "    files = find_files(directory)\n",
    "    id_reg_exp = re.compile(FILE_PATTERN)\n",
    "    print(\"files length: {}\".format(len(files)))\n",
    "    randomized_files = randomize_files(files)\n",
    "    for filename in randomized_files:\n",
    "        ids = id_reg_exp.findall(filename)\n",
    "        if not ids:\n",
    "            # The file name does not match the pattern containing ids, so\n",
    "            # there is no id.\n",
    "            category_id = None\n",
    "        else:\n",
    "            # The file name matches the pattern for containing ids.\n",
    "            category_id = int(ids[0][0])\n",
    "        audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "        audio = audio.reshape(-1, 1)\n",
    "        yield audio, filename, category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def trim_silence(audio, threshold):\n",
    "    '''Removes silence at the beginning and end of a sample.'''\n",
    "    energy = librosa.feature.rmse(audio)\n",
    "    frames = np.nonzero(energy > threshold)\n",
    "    indices = librosa.core.frames_to_samples(frames)[1]\n",
    "\n",
    "    # Note: indices can be an empty array, if the whole audio was silence.\n",
    "    return audio[indices[0]:indices[-1]] if indices.size else audio[0:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def not_all_have_id(files):\n",
    "    ''' Return true iff any of the filenames does not conform to the pattern\n",
    "        we require for determining the category id.'''\n",
    "    id_reg_exp = re.compile(FILE_PATTERN)\n",
    "    for file in files:\n",
    "        ids = id_reg_exp.findall(file)\n",
    "        if not ids:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import threading\n",
    "\n",
    "class AudioReader(object):\n",
    "    '''Generic background audio reader that preprocesses audio files\n",
    "    and enqueues them into a TensorFlow queue.'''\n",
    "\n",
    "    def __init__(self,\n",
    "                 audio_dir,\n",
    "                 coord,\n",
    "                 sample_rate,\n",
    "                 gc_enabled,\n",
    "                 receptive_field,\n",
    "                 sample_size=None,\n",
    "                 silence_threshold=None,\n",
    "                 queue_size=32):\n",
    "\n",
    "        self.audio_dir = audio_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.coord = coord\n",
    "        self.sample_size = sample_size\n",
    "        self.receptive_field = receptive_field\n",
    "        self.silence_threshold = silence_threshold\n",
    "        self.gc_enabled = gc_enabled\n",
    "        self.threads = []\n",
    "        self.sample_placeholder = tf.placeholder(dtype=tf.float32, shape=None)\n",
    "        self.queue = tf.PaddingFIFOQueue(queue_size,['float32'],shapes=[(None, 1)])\n",
    "        self.enqueue = self.queue.enqueue([self.sample_placeholder])\n",
    "\n",
    "        if self.gc_enabled:\n",
    "            self.id_placeholder = tf.placeholder(dtype=tf.int32, shape=())\n",
    "            self.gc_queue = tf.PaddingFIFOQueue(queue_size, ['int32'],shapes=[()])\n",
    "            self.gc_enqueue = self.gc_queue.enqueue([self.id_placeholder])\n",
    "\n",
    "        # TODO Find a better way to check this.\n",
    "        # Checking inside the AudioReader's thread makes it hard to terminate\n",
    "        # the execution of the script, so we do it in the constructor for now.\n",
    "        files = find_files(audio_dir)\n",
    "        if not files:\n",
    "            raise ValueError(\"No audio files found in '{}'.\".format(audio_dir))\n",
    "        if self.gc_enabled and not_all_have_id(files):\n",
    "            raise ValueError(\"Global conditioning is enabled, but file names \"\n",
    "                             \"do not conform to pattern having id.\")\n",
    "        # Determine the number of mutually-exclusive categories we will\n",
    "        # accomodate in our embedding table.\n",
    "        if self.gc_enabled:\n",
    "            _, self.gc_category_cardinality = get_category_cardinality(files)\n",
    "            # Add one to the largest index to get the number of categories,\n",
    "            # since tf.nn.embedding_lookup expects zero-indexing. This\n",
    "            # means one or more at the bottom correspond to unused entries\n",
    "            # in the embedding lookup table. But that's a small waste of memory\n",
    "            # to keep the code simpler, and preserves correspondance between\n",
    "            # the id one specifies when generating, and the ids in the\n",
    "            # file names.\n",
    "            self.gc_category_cardinality += 1\n",
    "            print(\"Detected --gc_cardinality={}\".format(self.gc_category_cardinality))\n",
    "        else:\n",
    "            self.gc_category_cardinality = None\n",
    "\n",
    "    def dequeue(self, num_elements):\n",
    "        output = self.queue.dequeue_many(num_elements)\n",
    "        return output\n",
    "\n",
    "    def dequeue_gc(self, num_elements):\n",
    "        return self.gc_queue.dequeue_many(num_elements)\n",
    "\n",
    "    def thread_main(self, sess):\n",
    "        stop = False\n",
    "        # Go through the dataset multiple times\n",
    "        while not stop:\n",
    "            iterator = load_generic_audio(self.audio_dir, self.sample_rate)\n",
    "            for audio, filename, category_id in iterator:\n",
    "                if self.coord.should_stop():\n",
    "                    stop = True\n",
    "                    break\n",
    "                if self.silence_threshold is not None:\n",
    "                    # Remove silence\n",
    "                    audio = trim_silence(audio[:, 0], self.silence_threshold)\n",
    "                    audio = audio.reshape(-1, 1)\n",
    "                    \"\"\"\n",
    "                    if audio.size == 0:\n",
    "                        print(\"Warning: {} was ignored as it contains only \"\n",
    "                              \"silence. Consider decreasing trim_silence \"\n",
    "                              \"threshold, or adjust volume of the audio.\"\n",
    "                              .format(filename))\n",
    "                    \"\"\"\n",
    "                audio = np.pad(audio, [[self.receptive_field, 0], [0, 0]],'constant')\n",
    "\n",
    "                if self.sample_size:\n",
    "                    # Cut samples into pieces of size receptive_field +\n",
    "                    # sample_size with receptive_field overlap\n",
    "                    while len(audio) > self.receptive_field:\n",
    "                        piece = audio[:(self.receptive_field + self.sample_size), :]\n",
    "                        sess.run(self.enqueue,feed_dict={self.sample_placeholder: piece})\n",
    "                        audio = audio[self.sample_size:, :]\n",
    "                        if self.gc_enabled:\n",
    "                            sess.run(self.gc_enqueue, feed_dict={self.id_placeholder: category_id})\n",
    "                else:\n",
    "                    sess.run(self.enqueue,feed_dict={self.sample_placeholder: audio})\n",
    "                    if self.gc_enabled:\n",
    "                        sess.run(self.gc_enqueue,feed_dict={self.id_placeholder: category_id})\n",
    "\n",
    "    def start_threads(self, sess, n_threads=1):\n",
    "        for _ in range(n_threads):\n",
    "            thread = threading.Thread(target=self.thread_main, args=(sess,))\n",
    "            thread.daemon = True  # Thread will close when parent quits.\n",
    "            thread.start()\n",
    "            self.threads.append(thread)\n",
    "        return self.threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
